# 네이버 블로그 크롤러 최종 개발 기획서
## 현재 완성된 버전 기준

**문서 버전**: 1.0  
**작성일**: 2025-01-03  
**최종 업데이트**: 2025-01-03  
**프로젝트 상태**: ✅ 완료

---

## 목차

1. [프로젝트 개요](#1-프로젝트-개요)
2. [프로젝트 목표](#2-프로젝트-목표)
3. [기술 스택 및 아키텍처](#3-기술-스택-및-아키텍처)
4. [주요 기능](#4-주요-기능)
5. [개발 일정](#5-개발-일정)
6. [완성된 기능](#6-완성된-기능)
7. [품질 보증](#7-품질-보증)
8. [리스크 관리](#8-리스크-관리)
9. [향후 계획](#9-향후-계획)
10. [참고 문서](#10-참고-문서)

---

## 1. 프로젝트 개요

### 1.1 프로젝트명
**네이버 블로그 크롤러 (Naver Blog Crawler)**

### 1.2 프로젝트 목적
네이버 블로그의 모바일 버전을 활용하여 특정 블로그의 모든 포스트를 체계적으로 수집하는 자동화 크롤러를 개발합니다.

### 1.3 프로젝트 범위
- **대상 플랫폼**: 네이버 블로그 모바일 버전 (m.blog.naver.com)
- **대상 사용자**: 블로그 콘텐츠 수집 및 분석이 필요한 사용자
- **지원 OS**: Windows 10/11 (현재 버전)
- **지원 언어**: 한국어 (현재 버전)

### 1.4 프로젝트 상태
- **현재 버전**: 1.0 (완료)
- **개발 완료일**: 2025-01-03
- **주요 기능**: ✅ 모두 완료

---

## 2. 프로젝트 목표

### 2.1 핵심 목표
1. **완전 자동화**: 사용자가 복잡한 설정 없이 바로 사용 가능
2. **안정성**: 중단 및 재개 기능으로 대량 크롤링 지원
3. **효율성**: 2단계 크롤링 전략으로 빠른 링크 수집 후 상세 크롤링
4. **데이터 완전성**: 해시태그, 댓글, 본문, 메타데이터 등 모든 정보 수집

### 2.2 성공 지표
- ✅ 블로그 ID 기반 크롤링 구현
- ✅ GUI 인터페이스 제공
- ✅ 중단 및 재개 기능 구현
- ✅ 체크포인트 관리 시스템 구현
- ✅ 배치 처리 기능 구현
- ✅ 해시태그 및 댓글 수집 기능 구현

---
## 3. 기술 스택 및 아키텍처

### 3.1 기술 스택

#### 3.1.1 프로그래밍 언어
- **Python 3.10+**: 메인 개발 언어

#### 3.1.2 핵심 라이브러리
- **Playwright 1.40.0+**: 웹 브라우저 자동화
- **Tkinter**: GUI 프레임워크 (Python 표준 라이브러리)
- **tqdm 4.66.1+**: 진행률 표시 (선택적)

#### 3.1.3 개발 도구
- **Git**: 버전 관리
- **Python venv**: 가상 환경 관리

### 3.2 시스템 아키텍처

```
┌─────────────────────────────────────────────────────┐
│                  GUI Layer (Tkinter)                │
│  ┌──────────────┐  ┌──────────────┐                │
│  │ 메인 화면    │  │ 진행 상황    │                │
│  └──────────────┘  └──────────────┘                │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│              Business Logic Layer                   │
│  ┌──────────────────────────────────────────────┐ │
│  │        Batch Crawler                          │ │
│  │  - 다중 블로그 처리                            │ │
│  │  - 체크포인트 관리                            │ │
│  └──────────────────────────────────────────────┘ │
│                        ↓                           │
│  ┌──────────────────────────────────────────────┐ │
│  │        Crawler Engine                         │ │
│  │  - Phase 1: 링크 수집                          │ │
│  │  - Phase 2: 상세 크롤링                       │ │
│  └──────────────────────────────────────────────┘ │
│                        ↓                           │
│  ┌──────────────────────────────────────────────┐ │
│  │        Parser                                 │ │
│  │  - 해시태그 추출                              │ │
│  │  - 댓글 추출                                  │ │
│  │  - 본문 추출                                  │ │
│  │  - 메타데이터 추출                            │ │
│  └──────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────┐
│              Infrastructure Layer                   │
│  ┌──────────────┐  ┌──────────────┐                │
│  │ Playwright   │  │ File I/O     │                │
│  │ Browser      │  │ JSON Export  │                │
│  └──────────────┘  └──────────────┘                │
└─────────────────────────────────────────────────────┘
```

### 3.3 디렉토리 구조

```
NaverBlogPlaywright/
├── src/
│   ├── crawler/              # 크롤링 엔진
│   │   ├── __init__.py
│   │   ├── engine.py         # 크롤링 엔진 (2단계 크롤링)
│   │   ├── parser.py         # HTML 파싱 (해시태그, 댓글, 본문)
│   │   └── batch_crawler.py  # 배치 처리
│   ├── gui/                  # GUI 인터페이스
│   │   ├── __init__.py
│   │   └── main_window.py    # 메인 윈도우
│   ├── utils/                # 유틸리티
│   │   ├── __init__.py
│   │   ├── checkpoint_manager.py  # 체크포인트 관리
│   │   ├── file_exporter.py        # 파일 출력
│   │   ├── file_splitter.py        # 파일 분할
│   │   ├── input_handler.py        # 입력 처리
│   │   └── exceptions.py            # 예외 처리
│   ├── __init__.py
│   └── models.py             # 데이터 모델
├── output/                   # 결과 파일 출력 디렉토리
├── checkpoints/              # 체크포인트 파일 저장 디렉토리
├── logs/                     # 로그 파일 디렉토리
├── main.py                   # 메인 실행 파일
├── requirements.txt          # Python 의존성
├── package.json              # Node.js 의존성 (Playwright)
├── playwright.config.js      # Playwright 설정
└── README.md                 # 프로젝트 설명
```

---
## 4. 주요 기능

### 4.1 핵심 기능

#### 4.1.1 블로그 ID 기반 크롤링 ✅
- **2단계 크롤링 전략**:
  1. Phase 1: 링크 수집 (스크롤 → 모든 링크 추출)
  2. Phase 2: 상세 크롤링 (각 링크 순회 → 데이터 수집)
- **스크롤 최적화**: 높이(px) 변화가 없을 때까지 스크롤 (횟수 제한 없음)
- **전체글 갯수 확인**: 전체글 버튼 클릭하여 목표 설정

#### 4.1.2 데이터 수집 ✅
- **기본 정보**: post_id, title, url, author, dates
- **메타데이터**: views, likes, comments, category, tags
- **본문 내용**: html, text, markdown, word_count, images, links
- **해시태그**: 확장 버튼 클릭 후 모든 해시태그 수집 ✅
- **댓글**: 댓글 버튼 클릭 후 모든 댓글 수집 ✅

#### 4.1.3 GUI 인터페이스 ✅
- **메인 화면**: 입력 방법 선택, 재개 옵션, 설정 요약
- **진행 상황 화면**: 프로그레스 바, 실시간 로그, 중단 버튼
- **결과 화면**: 결과 요약, 파일 경로, 폴더 열기

#### 4.1.4 중단 및 재개 기능 ✅
- **중단 처리**: 사용자가 중단 버튼 클릭 시 현재까지 데이터 저장
- **체크포인트 관리**: N개 포스트마다 자동 저장 (기본값: 10개)
- **재개 기능**: 체크포인트 파일로부터 자동 재개

#### 4.1.5 배치 처리 ✅
- **다중 블로그 처리**: 여러 블로그 ID를 하나의 작업으로 처리
- **통합 결과**: 모든 블로그의 결과를 하나의 JSON 파일로 통합
- **중복 제거**: URL 및 Post ID 기준 중복 제거

#### 4.1.6 파일 출력 ✅
- **JSON 형식**: 기본 형식 (구조화된 데이터)
- **CSV 형식**: 스프레드시트 호환 형식 (선택적)
- **JSONL 형식**: LLM 학습용 형식 (선택적)
- **파일 분할**: LLM 호환 파일 분할 (ChatGPT, Claude)

### 4.2 지원 기능

#### 4.2.1 입력 방법
- **단일 입력**: 블로그 ID 직접 입력
- **파일 업로드**: 텍스트 파일 또는 CSV 파일로 여러 블로그 ID 일괄 처리

#### 4.2.2 설정 옵션
- **저장 간격**: N개 포스트마다 자동 저장 (1~100, 기본값: 10)
- **파일 분할**: LLM 호환 파일 분할 사용 여부
- **LLM 프리셋**: ChatGPT, Claude, Custom 선택

---

## 5. 개발 일정

### 5.1 개발 단계별 일정

#### Phase 1: 기획 및 설계 (완료)
- **기간**: 초기 단계
- **작업 내용**:
  - 요구사항 분석
  - 시스템 아키텍처 설계
  - 데이터 모델 설계
- **결과물**: PRD, 기술 명세서

#### Phase 2: 핵심 기능 개발 (완료)
- **기간**: 개발 초기
- **작업 내용**:
  - 크롤링 엔진 구현
  - 기본 파서 구현
  - 데이터 모델 구현
- **결과물**: 크롤링 엔진, 기본 파서

#### Phase 3: 고급 기능 개발 (완료)
- **기간**: 개발 중기
- **작업 내용**:
  - 해시태그 수집 기능 구현 ✅
  - 댓글 수집 기능 구현 ✅
  - 스크롤 최적화 ✅
- **결과물**: 해시태그/댓글 파서, 스크롤 최적화

#### Phase 4: GUI 개발 (완료)
- **기간**: 개발 중후기
- **작업 내용**:
  - 메인 화면 구현
  - 진행 상황 화면 구현
  - 결과 화면 구현
  - 설정 대화상자 구현
- **결과물**: GUI 인터페이스

#### Phase 5: 안정화 및 테스트 (완료)
- **기간**: 개발 후기
- **작업 내용**:
  - 버그 수정
  - 에러 처리 개선
  - 성능 최적화
  - 사용자 테스트
- **결과물**: 안정화된 버전

### 5.2 주요 마일스톤

| 마일스톤 | 일정 | 상태 |
|---------|------|------|
| 기본 크롤링 기능 | 초기 | ✅ 완료 |
| 해시태그 수집 기능 | 중기 | ✅ 완료 |
| 댓글 수집 기능 | 중기 | ✅ 완료 |
| GUI 인터페이스 | 중후기 | ✅ 완료 |
| 중단/재개 기능 | 후기 | ✅ 완료 |
| 스크롤 최적화 | 후기 | ✅ 완료 |
| 최종 안정화 | 최종 | ✅ 완료 |

---
## 6. 완성된 기능

### 6.1 완료된 기능 목록

#### ✅ 블로그 ID 기반 크롤링
- 2단계 크롤링 전략 (링크 수집 → 상세 크롤링)
- 전체글 갯수 확인
- 스크롤 최적화 (높이 기반 종료, 횟수 제한 없음)
- JavaScript 기반 링크 수집

#### ✅ 데이터 수집
- **기본 정보**: post_id, title, url, author, published_date, modified_date
- **메타데이터**: views, likes, comments, category, tags
- **본문 내용**: html, text, markdown, word_count, images, links
- **해시태그**: 확장 버튼 클릭 후 모든 해시태그 수집
- **댓글**: 댓글 버튼 클릭 후 모든 댓글 수집 (다중 선택자 Fallback)

#### ✅ GUI 인터페이스
- 메인 화면 (입력 방법 선택, 재개 옵션, 설정 요약)
- 진행 상황 화면 (프로그레스 바, 실시간 로그, 중단 버튼)
- 결과 화면 (결과 요약, 파일 경로, 폴더 열기)
- 설정 대화상자

#### ✅ 중단 및 재개 기능
- 사용자 중단 처리 (현재까지 데이터 저장)
- 체크포인트 자동 저장 (N개 포스트마다)
- 체크포인트 파일로 재개
- 하위 호환성 유지

#### ✅ 배치 처리
- 다중 블로그 ID 처리
- 통합 결과 파일 생성
- 블로그별 진행 상황 추적
- 중복 제거 (URL, Post ID 기준)

#### ✅ 파일 출력
- JSON 형식 (기본)
- CSV 형식 (선택적)
- JSONL 형식 (선택적)
- 파일 분할 (LLM 호환)

#### ✅ 에러 처리
- 네트워크 오류 처리 (재시도 로직)
- 파싱 오류 처리 (기본값 사용)
- 블로그 오류 처리 (건너뛰기)
- 중단 처리 (데이터 저장)

### 6.2 기술적 성과

#### 6.2.1 스크롤 최적화
- **기존**: 고정 횟수 제한 (200회)
- **개선**: 높이(px) 변화 기반 종료 (횟수 제한 없음)
- **효과**: 모든 링크 수집 보장, 불필요한 스크롤 제거

#### 6.2.2 데이터 파싱 개선
- **해시태그**: 확장 버튼 클릭 → 다중 선택자 시도 → JavaScript Fallback
- **댓글**: 다중 선택자 전략 (tabpanel → ul.u_cbox_list → li.u_cbox_comment)
- **효과**: 높은 수집 성공률, 다양한 DOM 구조 대응

#### 6.2.3 안정성 향상
- **재시도 로직**: 포스트 크롤링 실패 시 최대 3회 재시도
- **부분 실패 허용**: 일부 포스트 실패해도 전체 작업 계속 진행
- **체크포인트 관리**: 중단 시 데이터 손실 방지

---

## 7. 품질 보증

### 7.1 코드 품질

#### 7.1.1 코드 구조
- **모듈화**: 기능별로 명확히 분리된 모듈
- **재사용성**: 유틸리티 함수 재사용 가능
- **가독성**: 명확한 함수명 및 주석

#### 7.1.2 에러 처리
- **예외 처리**: 모든 주요 기능에 try-except 블록
- **기본값 제공**: 파싱 실패 시 기본값 사용
- **로그 기록**: 모든 에러를 로그에 기록

#### 7.1.3 성능 최적화
- **메모리 관리**: 최근 100개 포스트만 메모리 유지
- **딜레이 최적화**: 최소 대기 시간 설정 (0.2초)
- **스크롤 최적화**: 높이 기반 종료로 불필요한 스크롤 제거

### 7.2 테스트 전략

#### 7.2.1 단위 테스트
- **파서 함수**: 각 파서 함수의 정확성 검증
- **유틸리티 함수**: 입력 처리, 파일 출력 등 검증

#### 7.2.2 통합 테스트
- **크롤링 엔진**: 전체 크롤링 프로세스 검증
- **GUI 인터페이스**: 사용자 시나리오 검증

#### 7.2.3 실제 사용 테스트
- **다양한 블로그**: 다양한 크기의 블로그로 테스트
- **대량 크롤링**: 100개 이상 포스트 수집 테스트
- **재개 기능**: 중단 및 재개 시나리오 테스트

### 7.3 문서화

#### 7.3.1 코드 문서화
- **Docstring**: 모든 주요 함수에 docstring 제공
- **주석**: 복잡한 로직에 설명 주석 추가

#### 7.3.2 사용자 문서화
- **README.md**: 설치 및 사용 방법 안내
- **PRD**: 제품 요구사항 문서
- **기능상세명세서**: 각 기능의 상세 명세
- **UI/UX 명세서**: 사용자 인터페이스 명세

---
## 8. 리스크 관리

### 8.1 기술적 리스크

#### 8.1.1 네이버 블로그 구조 변경
- **리스크**: 네이버 블로그의 DOM 구조가 변경되면 파싱 실패
- **완화 방안**: 
  - ✅ 다중 선택자 전략 사용
  - ✅ JavaScript Fallback 구현
  - ✅ 기본값 제공으로 부분 수집 계속 진행

#### 8.1.2 네트워크 불안정
- **리스크**: 네트워크 연결이 불안정하면 크롤링 실패
- **완화 방안**:
  - ✅ 재시도 로직 구현 (최대 3회)
  - ✅ 타임아웃 설정
  - ✅ 부분 실패 허용

#### 8.1.3 대량 크롤링 시 메모리 부족
- **리스크**: 대량 크롤링 시 메모리 부족 발생 가능
- **완화 방안**:
  - ✅ 최근 100개 포스트만 메모리 유지
  - ✅ 체크포인트 저장으로 주기적 메모리 해제
  - ✅ 스트리밍 출력으로 메모리 효율성 확보

### 8.2 운영 리스크

#### 8.2.1 이용약관 준수
- **리스크**: 네이버 블로그 이용약관 위반 가능성
- **완화 방안**:
  - ⚠️ 요청 간 딜레이 설정 (0.5초 이상)
  - ⚠️ robots.txt 확인 필요
  - ⚠️ 사용자에게 이용약관 준수 안내

#### 8.2.2 서버 부하
- **리스크**: 과도한 요청으로 서버 부하 발생
- **완화 방안**:
  - ✅ 딜레이 설정 (기본 0.5초)
  - ✅ 단일 스레드 처리
  - ✅ 타임아웃 설정

### 8.3 사용자 리스크

#### 8.3.1 잘못된 입력
- **리스크**: 사용자가 잘못된 블로그 ID 입력
- **완화 방안**:
  - ✅ 입력 검증 기능 구현
  - ✅ 명확한 에러 메시지 제공
  - ✅ 파일 업로드 시 유효성 검사

#### 8.3.2 데이터 손실
- **리스크**: 크롤링 중단 시 데이터 손실
- **완화 방안**:
  - ✅ 중단 시 자동 저장 기능
  - ✅ 체크포인트 관리 시스템
  - ✅ 재개 기능 제공

---

## 9. 향후 계획

### 9.1 기능 개선 계획

#### 9.1.1 단기 계획 (1~3개월)
- [ ] 키워드 기반 검색 크롤링
- [ ] 날짜 범위 필터링
- [ ] 카테고리별 크롤링
- [ ] 이미지 다운로드 기능

#### 9.1.2 중기 계획 (3~6개월)
- [ ] CSV/Excel 직접 출력
- [ ] 증분 크롤링 (변경된 포스트만 수집)
- [ ] 프록시 지원
- [ ] 캐싱 기능

#### 9.1.3 장기 계획 (6개월 이상)
- [ ] 멀티스레드 크롤링 (병렬 처리)
- [ ] 웹 인터페이스 (웹 애플리케이션)
- [ ] REST API 제공
- [ ] 클라우드 배포

### 9.2 성능 개선 계획

#### 9.2.1 속도 개선
- [ ] 멀티스레드 크롤링으로 병렬 처리
- [ ] 프록시 풀 사용으로 동시 요청 증가
- [ ] 캐싱으로 중복 요청 제거

#### 9.2.2 메모리 최적화
- [ ] 스트리밍 파싱으로 메모리 사용량 감소
- [ ] 압축 저장으로 파일 크기 감소

### 9.3 UI/UX 개선 계획

#### 9.3.1 시각적 개선
- [ ] 다크 모드 지원
- [ ] 아이콘 추가
- [ ] 더 나은 색상 스킴

#### 9.3.2 사용성 개선
- [ ] 드래그 앤 드롭 파일 업로드
- [ ] 진행률 세부 정보 (블로그별, 포스트별)
- [ ] 예상 완료 시간 정확도 향상
- [ ] 키보드 단축키 추가

### 9.4 플랫폼 확장 계획

#### 9.4.1 운영체제 지원
- [ ] macOS 지원
- [ ] Linux 지원

#### 9.4.2 언어 지원
- [ ] 영어 인터페이스
- [ ] 일본어 인터페이스

---
## 10. 참고 문서

### 10.1 프로젝트 문서

#### 10.1.1 요구사항 문서
- **PRD_NaverBlogCrawler_Current.md**: 제품 요구사항 문서 (현재 버전)
- **DETAILED_FUNCTIONAL_SPEC_Current.md**: 기능상세명세서 (현재 버전)
- **UI_UX_SPEC_Current.md**: UI/UX 명세서 (현재 버전)

#### 10.1.2 기술 문서
- **README.md**: 프로젝트 개요 및 설치 방법
- **requirements.txt**: Python 의존성 목록
- **package.json**: Node.js 의존성 목록 (Playwright)

#### 10.1.3 개발 문서
- **mobileNAVERBlog.txt**: 네이버 블로그 DOM 구조 정보

### 10.2 외부 문서

#### 10.2.1 기술 참고 문서
- **Playwright 공식 문서**: https://playwright.dev/python/
- **Tkinter 공식 문서**: https://docs.python.org/3/library/tkinter.html
- **네이버 블로그 이용약관**: 네이버 이용약관 확인 필요

#### 10.2.2 관련 표준
- **JSON 표준**: RFC 8259
- **CSV 표준**: RFC 4180

---

## 11. 프로젝트 요약

### 11.1 개발 완료 현황

#### ✅ 완료된 기능
- 블로그 ID 기반 크롤링 (2단계 전략)
- 해시태그 수집 기능
- 댓글 수집 기능
- GUI 인터페이스
- 중단 및 재개 기능
- 체크포인트 관리 시스템
- 배치 처리 기능
- 파일 출력 (JSON, CSV, JSONL)
- 파일 분할 기능 (LLM 호환)
- 스크롤 최적화

#### ✅ 완료된 문서
- PRD (제품 요구사항 문서)
- 기능상세명세서
- UI/UX 명세서
- 개발 기획서 (본 문서)

### 11.2 기술적 성과

#### 11.2.1 성능
- **스크롤 속도**: 높이 기반 종료로 최적화
- **데이터 수집률**: 다중 선택자 전략으로 높은 성공률
- **메모리 효율**: 최근 포스트만 메모리 유지

#### 11.2.2 안정성
- **에러 처리**: 모든 주요 기능에 예외 처리
- **재시도 로직**: 네트워크 오류 시 자동 재시도
- **데이터 보호**: 중단 시 자동 저장

#### 11.2.3 사용성
- **직관적 인터페이스**: 복잡한 설정 없이 바로 사용 가능
- **명확한 피드백**: 실시간 진행 상황 표시
- **재개 기능**: 중단된 작업 쉽게 재개

### 11.3 프로젝트 통계

#### 11.3.1 코드 규모
- **주요 모듈**: 10개 이상
- **주요 함수**: 30개 이상
- **총 코드 라인**: 약 2,000줄 이상

#### 11.3.2 기능 규모
- **핵심 기능**: 6개
- **지원 기능**: 5개 이상
- **GUI 화면**: 3개

### 11.4 향후 개선 방향

#### 11.4.1 단기 개선
- 키워드 기반 크롤링
- 날짜 범위 필터링
- 이미지 다운로드

#### 11.4.2 중장기 개선
- 멀티스레드 크롤링
- 웹 인터페이스
- REST API 제공

---

## 12. 결론

### 12.1 프로젝트 성공 요인
1. **명확한 요구사항**: 초기 단계에서 명확한 요구사항 정의
2. **단계적 개발**: 핵심 기능부터 시작하여 점진적 확장
3. **안정성 우선**: 에러 처리 및 재시도 로직으로 안정성 확보
4. **사용자 중심**: GUI 인터페이스로 사용성 향상

### 12.2 학습 내용
1. **웹 크롤링**: Playwright를 활용한 고급 웹 크롤링 기법
2. **GUI 개발**: Tkinter를 활용한 사용자 인터페이스 개발
3. **데이터 파싱**: 다양한 DOM 구조에 대응하는 파싱 전략
4. **상태 관리**: 체크포인트 관리로 대량 크롤링 지원

### 12.3 프로젝트 의의
이 프로젝트는 네이버 블로그의 대량 콘텐츠 수집을 자동화하는 완전한 솔루션을 제공합니다. GUI 인터페이스, 중단/재개 기능, 체크포인트 관리 등 실용적인 기능을 포함하여 사용자가 쉽고 안전하게 크롤링 작업을 수행할 수 있습니다.

---

**문서 끝**

**작성자**: 개발팀  
**검토일**: 2025-01-03  
**승인일**: 2025-01-03
