# 네이버 블로그 크롤러 PRD (Product Requirements Document)
## 현재 완성된 버전 기준

**문서 버전**: 1.0  
**작성일**: 2025-01-03  
**최종 업데이트**: 2025-01-03

---

## 1. 개요

### 1.1 프로젝트 목적
네이버 블로그의 모바일 버전을 활용하여 특정 블로그의 모든 포스트를 체계적으로 수집하는 자동화 크롤러를 제공합니다.

### 1.2 핵심 가치
- **완전 자동화**: GUI를 통한 쉬운 사용
- **안정성**: 중단 및 재개 기능으로 대량 크롤링 지원
- **효율성**: 2단계 크롤링 전략으로 빠른 링크 수집 후 상세 크롤링
- **데이터 완전성**: 해시태그, 댓글, 본문, 메타데이터 등 모든 정보 수집

### 1.3 기술 스택
- **언어**: Python 3.10+
- **웹 자동화**: Playwright
- **GUI 프레임워크**: Tkinter
- **데이터 저장**: JSON

---## 2. 기능 요구사항

### 2.1 블로그 ID 기반 크롤링

#### 2.1.1 입력 방법
- **단일 블로그 ID 입력**: GUI에서 직접 블로그 ID 입력
- **파일 업로드**: 텍스트 파일 또는 CSV 파일로 여러 블로그 ID 일괄 처리
  - 형식: 한 줄에 하나의 블로그 ID
  - 예시: `blog_id_1`, `blog_id_2`

#### 2.1.2 크롤링 프로세스 (2단계)
**Phase 1: 링크 수집**
1. 블로그 메인 페이지 접속
2. 전체글 갯수 확인 (전체글 버튼 클릭 → 갯수 수집 → 닫기 버튼 클릭)
3. 스크롤 다운하여 모든 링크 수집
   - 높이(px) 변화가 없을 때까지 스크롤 (횟수 제한 없음)
   - 높이 변화가 3번 연속 없으면 종료
   - 최소 대기 시간: 0.2초 (콘텐츠 로딩 확보)
4. JavaScript로 DOM 순서대로 모든 포스트 링크 추출

**Phase 2: 상세 크롤링**
1. 수집된 링크를 순서대로 순회
2. 각 포스트 상세 페이지 접속
3. 데이터 수집 순서:
   - 메타데이터 (조회수, 좋아요, 댓글 수)
   - 본문 내용
   - **해시태그** (확장 버튼 클릭 후 수집)
   - **댓글** (댓글 버튼 클릭 후 수집)

#### 2.1.3 수집 데이터 항목
각 포스트에서 수집하는 데이터:

**기본 정보**
- `post_id`: 포스트 고유 ID
- `title`: 포스트 제목
- `url`: 포스트 URL
- `author`: 작성자 정보
  - `blog_id`: 블로그 ID
  - `nickname`: 닉네임
- `published_date`: 작성일시
- `modified_date`: 수정일시 (있는 경우)

**메타데이터**
- `views`: 조회수
- `likes`: 공감 수
- `comments`: 댓글 수
- `category`: 카테고리 (있는 경우)
- `tags`: 해시태그 목록

**본문 내용**
- `html`: HTML 원본
- `text`: 텍스트 (이스케이프 문자 제거)
- `markdown`: 마크다운 형식 (간단 변환)
- `word_count`: 단어 수
- `images`: 이미지 URL 목록
- `links`: 링크 URL 목록

**댓글**
- `author`: 댓글 작성자 닉네임
- `content`: 댓글 내용
- `date`: 댓글 작성일시 (있는 경우)
- `likes`: 댓글 공감 수

---### 2.2 GUI 인터페이스

#### 2.2.1 메인 화면
- **입력 방법 선택**: 라디오 버튼으로 단일 입력/파일 업로드 선택
- **재개 옵션**: 중단된 크롤링 재개 체크박스
- **설정 요약**: 현재 저장 간격, 파일 분할 여부, 출력 형식 표시
- **주요 버튼**: 크롤링 시작, 설정, 도움말, 종료

#### 2.2.2 진행 상황 화면
- **전체 진행률**: 프로그레스 바
- **로그 영역**: 실시간 크롤링 로그 (스크롤 가능)
- **중단 버튼**: 크롤링 중단 (확인 다이얼로그 후 중단)
- **메인으로 버튼**: 메인 화면으로 복귀

#### 2.2.3 결과 화면
- **크롤링 결과 요약**: 수집된 포스트 수, 출력 파일 경로
- **중단 상태 표시**: 중단된 경우 경고 메시지 및 재개 안내
- **폴더 열기 버튼**: 결과 파일이 있는 폴더 열기
- **다시 크롤링 버튼**: 메인 화면으로 복귀

#### 2.2.4 설정 화면
- **저장 간격**: 포스트 수마다 자동 저장 (1~100, 기본값: 10)
- **파일 분할**: LLM 호환 파일 분할 사용 여부
- **LLM 프리셋**: ChatGPT, Claude, Custom 선택

### 2.3 중단 및 재개 기능

#### 2.3.1 중단 기능
- **중단 버튼**: GUI에서 "중단" 버튼 클릭 시 확인 다이얼로그 표시
- **중단 처리**:
  - 현재까지 수집된 데이터를 결과 파일로 즉시 저장
  - 체크포인트 파일에 진행 상황 저장
  - 브라우저 종료
  - 중단 상태 표시

#### 2.3.2 체크포인트 관리
- **자동 저장**: N개 포스트마다 자동 저장 (기본값: 10개)
- **체크포인트 파일 위치**: `checkpoints/` 디렉토리
- **체크포인트 파일명**: `batch_YYYYMMDD_HHMMSS.json`
- **체크포인트 내용**:
  - 작업 정보 (크롤링 타입, 블로그 ID 목록, 상태)
  - 블로그별 진행 상황
  - 최근 수집된 포스트 (최대 100개)
  - 오류 로그

#### 2.3.3 재개 기능
- **체크포인트 파일 선택**: GUI에서 체크포인트 파일 선택
- **자동 재개**: 완료되지 않은 블로그만 재개
- **진행 상황 유지**: 이전에 수집된 데이터 유지하며 이어서 크롤링

---### 2.4 배치 처리

#### 2.4.1 다중 블로그 처리
- **일괄 처리**: 여러 블로그 ID를 하나의 작업으로 처리
- **통합 결과**: 모든 블로그의 결과를 하나의 JSON 파일로 통합
- **블로그별 진행 상황 추적**: 각 블로그의 상태를 개별 추적

#### 2.4.2 중복 제거
- **URL 기반 중복 제거**: 동일 URL 수집 방지
- **Post ID 기반 중복 제거**: 동일 Post ID 수집 방지
- **체크포인트 기반 중복 제거**: 재개 시 이미 수집된 포스트 제외

### 2.5 파일 출력

#### 2.5.1 출력 형식
- **JSON**: 기본 형식 (구조화된 데이터)
- **CSV**: 스프레드시트 호환 형식 (선택적)
- **JSONL**: LLM 학습용 형식 (선택적)

#### 2.5.2 출력 파일 구조
```json
{
  "crawl_info": {
    "crawl_type": "blog_id",
    "total_blog_ids": 5,
    "processed_blog_ids": 5,
    "failed_blog_ids": 0,
    "total_posts": 150,
    "crawl_date": "2025-01-03T12:00:00",
    "sort_order": "crawl_order"
  },
  "posts": [
    {
      "post_id": "...",
      "title": "...",
      "author": {
        "blog_id": "...",
        "nickname": "..."
      },
      "published_date": "...",
      "modified_date": null,
      "url": "...",
      "metadata": {
        "views": 100,
        "likes": 10,
        "comments": 5,
        "category": null,
        "tags": ["태그1", "태그2"]
      },
      "content": {
        "text": "...",
        "word_count": 500,
        "images": ["url1", "url2"],
        "links": ["url1", "url2"]
      },
      "comments": [
        {
          "author": "...",
          "content": "...",
          "date": "...",
          "likes": 0
        }
      ]
    }
  ]
}
```

#### 2.5.3 파일 분할 (선택적)
- **LLM 호환 분할**: ChatGPT (50MB), Claude (100MB), Custom
- **자동 분할**: 설정된 최대 파일 크기를 초과 시 자동 분할
- **인덱스 파일**: 분할된 파일 목록 및 메타데이터 포함

---## 3. 기술 사양

### 3.1 크롤링 엔진

#### 3.1.1 브라우저 설정
- **모바일 모드**: iPhone 12 시뮬레이션
- **User Agent**: 모바일 User Agent 사용
- **Viewport**: 390x844 (iPhone 12)
- **Headless 모드**: 비활성화 (디버깅 및 스크롤 확인을 위해)

#### 3.1.2 스크롤 최적화
- **높이 기반 종료**: 높이(px) 변화가 없으면 스크롤 종료
- **횟수 제한 없음**: 높이 변화가 있을 때까지 무제한 스크롤
- **안정화 확인**: 높이 변화가 3번 연속 없으면 최종 확인 후 종료
- **최소 대기 시간**: 0.2초 (콘텐츠 로딩 확보)

#### 3.1.3 DOM 선택자 전략
- **다중 선택자 시도**: 각 요소에 대해 여러 선택자 순차 시도
- **JavaScript 기반 추출**: DOM 순서 보장을 위한 JavaScript 평가
- **Fallback 메커니즘**: 기본 선택자 실패 시 대체 방법 사용

#### 3.1.4 에러 처리
- **재시도 로직**: 포스트 크롤링 실패 시 최대 3회 재시도
- **타임아웃 처리**: 페이지 로딩 타임아웃 시 재시도
- **부분 실패 허용**: 일부 포스트 실패해도 전체 작업 계속 진행

### 3.2 데이터 파싱

#### 3.2.1 해시태그 수집
1. 해시태그 확장 버튼 클릭: `button.tag__tFC3j.expand_btn__oaNLH[data-click-area="pst.tagmore"]`
2. 해시태그 요소 추출: `a.tag__tFC3j[data-click-area="pst.tag"]`
3. JavaScript Fallback: Playwright Locator 실패 시 JavaScript 직접 추출

#### 3.2.2 댓글 수집
1. 댓글 버튼 클릭: `button.comment_btn__TUucZ[data-click-area="pst.re"]`
2. 댓글 로딩 대기: 5초 대기 후 추가 2초 안정화
3. JavaScript 기반 수집: `tabpanel > ul.u_cbox_list > li.u_cbox_comment`
4. 다중 선택자 Fallback: 여러 방법으로 댓글 요소 찾기

#### 3.2.3 본문 추출
- **HTML 원본**: `.se-main-container` 또는 `.post-content`
- **텍스트 추출**: HTML 태그 제거 후 텍스트만 추출
- **마크다운 변환**: 기본적인 HTML → Markdown 변환
- **이미지/링크 추출**: 본문 내 모든 이미지 및 링크 URL 수집

---### 3.3 로깅 시스템

#### 3.3.1 로그 레벨
- **INFO**: 일반 정보 (단계별 진행 상황)
- **WARNING**: 경고 (높이 변화 없음, 전체글 갯수 불일치 등)
- **ERROR**: 오류 (크롤링 실패, 파싱 오류 등)
- **DEBUG**: 디버그 정보 (상세한 파싱 과정)

#### 3.3.2 로그 출력
- **파일 로그**: `logs/crawler.log`
- **콘솔 로그**: 표준 출력
- **GUI 로그**: 진행 상황 화면의 로그 영역

#### 3.3.3 로그 형식
```
[YYYY-MM-DD HH:MM:SS] [단계] 메시지
[YYYY-MM-DD HH:MM:SS] [경고] 메시지
[YYYY-MM-DD HH:MM:SS] [오류] 메시지
```

### 3.4 성능 최적화

#### 3.4.1 딜레이 설정
- **기본 딜레이**: 0.5초 (요청 간 대기 시간)
- **스크롤 대기**: 0.2초 (최소 대기 시간)
- **안정화 대기**: 1초 (최종 높이 확인)

#### 3.4.2 메모리 관리
- **체크포인트 저장**: 최근 100개 포스트만 메모리에 유지
- **스트리밍 출력**: 대량 데이터도 메모리 효율적으로 처리

#### 3.4.3 병렬 처리
- **GUI 스레드**: 크롤링 작업을 별도 스레드에서 실행
- **비동기 처리**: 브라우저 작업과 데이터 저장 분리

---## 4. 사용자 인터페이스

### 4.1 화면 흐름

```
메인 화면
  ├─ 입력 방법 선택
  ├─ 블로그 ID 입력 / 파일 업로드
  ├─ 재개 옵션 선택 (선택적)
  └─ 크롤링 시작 버튼
       ↓
진행 상황 화면
  ├─ 전체 진행률 표시
  ├─ 실시간 로그
  ├─ 중단 버튼
  └─ 메인으로 버튼
       ↓
결과 화면
  ├─ 크롤링 결과 요약
  ├─ 출력 파일 경로
  ├─ 폴더 열기 버튼
  └─ 다시 크롤링 버튼
```

### 4.2 주요 버튼 및 기능

#### 메인 화면
- **크롤링 시작**: 입력 검증 후 크롤링 시작
- **설정**: 저장 간격, 파일 분할 등 설정 변경
- **도움말**: 사용 방법 안내
- **종료**: 애플리케이션 종료

#### 진행 상황 화면
- **중단**: 크롤링 중단 (확인 다이얼로그)
- **메인으로**: 메인 화면으로 복귀

#### 결과 화면
- **폴더 열기**: 결과 파일이 있는 폴더 열기
- **다시 크롤링**: 메인 화면으로 복귀
- **종료**: 애플리케이션 종료

---## 5. 데이터 모델

### 5.1 Post 객체
```python
@dataclass
class Post:
    post_id: str
    title: str
    author: Author
    published_date: datetime
    modified_date: Optional[datetime]
    url: str
    metadata: PostMetadata
    content: PostContent
    comments: List[Comment]
```

### 5.2 Author 객체
```python
@dataclass
class Author:
    blog_id: str
    nickname: str
```

### 5.3 PostMetadata 객체
```python
@dataclass
class PostMetadata:
    views: int
    likes: int
    comments: int
    category: Optional[str]
    tags: List[str]
```

### 5.4 PostContent 객체
```python
@dataclass
class PostContent:
    html: str
    text: str
    markdown: str
    word_count: int
    images: List[str]
    links: List[str]
```

### 5.5 Comment 객체
```python
@dataclass
class Comment:
    author: str
    content: str
    date: Optional[datetime]
    likes: int
```

---## 6. 에러 처리 및 예외 상황

### 6.1 네트워크 오류
- **타임아웃**: 페이지 로딩 타임아웃 시 재시도 (최대 3회)
- **연결 오류**: 네트워크 연결 실패 시 오류 로그 기록 후 다음 블로그로 진행

### 6.2 파싱 오류
- **요소 찾기 실패**: 다중 선택자 시도 후 실패 시 기본값 사용
- **데이터 추출 실패**: 부분 데이터라도 수집하여 진행

### 6.3 블로그 오류
- **블로그 없음**: `BlogNotFoundError` 발생, 해당 블로그 건너뛰기
- **접근 불가**: 권한 없음 또는 비공개 블로그, 오류 로그 기록 후 건너뛰기

### 6.4 중단 처리
- **사용자 중단**: 중단 버튼 클릭 시 현재까지 데이터 저장 후 종료
- **예외 발생**: 예외 발생 시 체크포인트 저장 후 오류 보고

## 7. 성능 요구사항

### 7.1 크롤링 속도
- **링크 수집**: 평균 1~2초/페이지 (스크롤 시간 포함)
- **상세 크롤링**: 평균 2~3초/포스트 (딜레이 0.5초 포함)
- **대량 크롤링**: 100개 포스트 약 5~7분

### 7.2 메모리 사용량
- **기본 메모리**: 약 200~300MB (브라우저 포함)
- **대량 크롤링**: 최대 500MB (최근 포스트만 메모리 유지)

### 7.3 파일 크기
- **JSON 파일**: 포스트당 약 5~10KB
- **100개 포스트**: 약 500KB~1MB
- **1000개 포스트**: 약 5~10MB

---## 8. 보안 및 제한사항

### 8.1 사용 제한
- **네이버 블로그 이용약관 준수**: 크롤링 목적 및 사용 범위 제한
- **robots.txt 준수**: 네이버 블로그의 robots.txt 정책 확인 필요
- **요청 간 딜레이**: 기본 0.5초 이상 유지 (서버 부하 방지)

### 8.2 데이터 사용
- **개인정보 보호**: 수집된 데이터의 개인정보 보호 책임은 사용자에게 있음
- **저작권**: 블로그 콘텐츠의 저작권은 원작자에게 있음

### 8.3 기술적 제한
- **모바일 버전 전용**: 데스크톱 버전은 지원하지 않음
- **동적 콘텐츠**: JavaScript로 동적으로 로드되는 콘텐츠는 대기 시간 필요

## 9. 향후 개선 사항

### 9.1 기능 개선
- [ ] 키워드 기반 검색 크롤링
- [ ] 날짜 범위 필터링
- [ ] 카테고리별 크롤링
- [ ] 이미지 다운로드 기능
- [ ] CSV/Excel 직접 출력

### 9.2 성능 개선
- [ ] 멀티스레드 크롤링 (병렬 처리)
- [ ] 프록시 지원
- [ ] 캐싱 기능
- [ ] 증분 크롤링 (변경된 포스트만 수집)

### 9.3 UI/UX 개선
- [ ] 다크 모드 지원
- [ ] 실시간 통계 표시
- [ ] 크롤링 예상 시간 계산
- [ ] 내보내기 형식 선택 UI

---## 10. 부록

### 10.1 주요 파일 구조
```
src/
├── crawler/
│   ├── engine.py          # 크롤링 엔진 (2단계 크롤링)
│   ├── parser.py          # HTML 파싱 (해시태그, 댓글, 본문)
│   └── batch_crawler.py   # 배치 처리
├── gui/
│   └── main_window.py     # GUI 메인 윈도우
├── utils/
│   ├── checkpoint_manager.py  # 체크포인트 관리
│   ├── file_exporter.py       # 파일 출력
│   └── input_handler.py       # 입력 처리
└── models.py              # 데이터 모델
```

### 10.2 주요 함수

#### 크롤링 엔진
- `crawl_by_blog_id()`: 블로그 ID 기반 크롤링
- `_collect_all_post_links()`: Phase 1 - 링크 수집
- `crawl_post_detail_mobile()`: Phase 2 - 상세 크롤링

#### 파서
- `extract_tags()`: 해시태그 추출
- `extract_comments()`: 댓글 추출
- `extract_content()`: 본문 추출
- `extract_metadata()`: 메타데이터 추출

#### 배치 처리
- `crawl_multiple_blog_ids()`: 다중 블로그 크롤링
- `resume_crawling()`: 체크포인트에서 재개

### 10.3 설정 파일
- **requirements.txt**: Python 패키지 의존성
- **package.json**: Node.js 의존성 (Playwright)
- **playwright.config.js**: Playwright 설정

### 10.4 출력 디렉토리
- **output/**: 결과 파일 저장 디렉토리
- **checkpoints/**: 체크포인트 파일 저장 디렉토리
- **logs/**: 로그 파일 저장 디렉토리

## 11. 변경 이력

### 버전 1.0 (2025-01-03)
- ✅ 2단계 크롤링 전략 구현 (링크 수집 → 상세 크롤링)
- ✅ 스크롤 최적화 (높이 기반 종료, 횟수 제한 없음)
- ✅ 해시태그 수집 기능 구현
- ✅ 댓글 수집 기능 구현 (다중 선택자 Fallback)
- ✅ 중단 및 재개 기능 구현
- ✅ GUI 인터페이스 구현
- ✅ 체크포인트 관리 시스템 구현
- ✅ 배치 처리 기능 구현
- ✅ 다중 선택자 Fallback 메커니즘 구현

---

**문서 끝**
